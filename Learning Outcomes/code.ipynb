{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMgV2NWmDh2i"
   },
   "outputs": [],
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9zBOjhbODh2j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from astropy.table import Table\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(r\"student-data.csv\")\n",
    "dfv = pd.read_csv(r\"student-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCueiPMxDh2m"
   },
   "source": [
    "# Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gIofgcGKDh2q"
   },
   "outputs": [],
   "source": [
    "domain = {\"KNOWLEDGE\":{\"Write\", \"List\", \"Label\", \"Name\", \"State\", \"Define\", \"Count\", \"Describe\", \"Draw\", \"Find\", \"Identify\", \"Match\", \n",
    "                        \"Quote\", \"Recall\", \"Recite\", \"Sequence\", \"Tell\", \"Arrange\", \"Duplicate\", \"Memorize\", \"Order\", \"Outline\", \n",
    "                        \"Recognize\", \"Relate\", \"Repeat\", \"Reproduce\", \"Select\", \"Choose\", \"Copy\", \"How\", \"Listen\", \"Locate\",\n",
    "\t\t\t\t\t\t\"Memorise\", \"Observe\", \"Omit\", \"Read\", \"Recognise\", \"Record\", \"Remember\", \"Retell\", \"Show\", \"Spell\",\n",
    "\t\t\t\t\t\t\"Trace\", \"What\", \"When\", \"Where\", \"Which\", \"Who\", \"Why\"},\n",
    "          \"COMPREHENSION\":{\"Explain\", \"Summarize\", \"Paraphrase\", \"Describe\", \"Illustrate\", \"Conclude\", \"Demonstrate\", \"Discuss\",\n",
    "\t\t\t\t\t\t   \"Generalize\", \"Identify\", \"Interpret\", \"Predict\", \"Report\", \"Restate\", \"Review\", \"Tell\", \"Classify\",\n",
    "\t\t\t\t\t\t   \"Convert\", \"Defend\", \"Distinguish\", \"Estimate\", \"Express\", \"Extend\", \"Give example\", \"Indicate\",\n",
    "\t\t\t\t\t\t   \"Infer\", \"Locate\", \"Recognize\", \"Rewrite\", \"Select\", \"Translate\", \"Ask\", \"Cite\", \"Compare\",\n",
    "\t\t\t\t\t\t   \"Contrast\", \"Generalise\", \"Give examples\", \"Match\", \"Observe\", \"Outline\", \"Purpose\", \"Relate\",\n",
    "\t\t\t\t\t\t   \"Rephrase\", \"Show\", \"Summarise\"},\n",
    "          \"APPLICATION\":{\"Use\", \"Compute\", \"Solve\", \"Demonstrate\", \"Apply\", \"Construct\", \"Change\", \"Choose\", \"Dramatize\", \"Interview\",\n",
    "\t\t\t\t\t\t \"Prepare\", \"Produce\", \"Select\", \"Show\", \"Transfer\", \"Discover\", \"Employ\", \"Illustrate\",\n",
    "\t\t\t\t\t\t \"Interpret\", \"Manipulate\",\"Modify\", \"Operate\", \"Practice\", \"Predict\", \"Relate schedule\", \"Sketch\",\n",
    "\t\t\t\t\t\t \"Use write\", \"Act\", \"Administer\", \"Associate\", \"Build\", \"Calculate\", \"Categorise\", \"Classify\",\n",
    "\t\t\t\t\t\t \"Connect\", \"Correlation\", \"Develop\", \"Dramatise\", \"Experiment\", \"With\", \"Group\", \"Identify\",\n",
    "\t\t\t\t\t\t \"Link\", \"Make use of\", \"Model\", \"Organise\", \"Perform\", \"Plan\", \"Relate\", \"Represent\", \"Simulate\",\n",
    "\t\t\t\t\t\t \"Summarise\", \"Teach\", \"Translate\"},\n",
    "          \"ANALYSIS\":{\"Analyse\", \"Categorize\", \"Compare\", \"Contrast\", \"Separate\", \"Characterize\", \"Classify\", \"Debate\", \"Deduce\", \n",
    "\t\t\t\t\t  \"Diagram\", \"Differentiate\", \"Discriminate\", \"Distinguish\", \"Examine\", \"Outline\", \"Relate\", \"Research\", \n",
    "\t\t\t\t\t  \"Appraise\", \"Breakdown\", \"Calculate\", \"Criticize\", \"Derive\", \"Experiment\", \"Identify\", \"Illustrate\", \n",
    "\t\t\t\t\t  \"Infer\", \"Interpret\", \"Model\", \"Outline\", \"Point out\", \"Question\", \"Select\", \"Subdivide\", \"Test\", \n",
    "\t\t\t\t\t  \"Arrange\", \"Assumption\", \"Categorise\", \"Cause and\", \"Effect\", \"Choose\", \"Difference\", \"Discover\", \n",
    "\t\t\t\t\t  \"Dissect\", \"Distinction\", \"Divide\", \"Establish\", \"Find\", \"Focus\", \"Function\", \"Group\", \"Highlight\", \n",
    "\t\t\t\t\t  \"In-depth\", \"Discussion\", \"Inference\", \"Inspect\", \"Investigate\", \"Isolate\", \"List\", \"Motive\", \"Omit\", \n",
    "\t\t\t\t\t  \"Order\", \"Organise\", \"Point out\", \"Prioritize\", \"Rank\", \"Reason\", \"Relationships\", \"Reorganise\", \"See\", \n",
    "\t\t\t\t\t  \"Similar to\", \"Simplify\", \"Survey\", \"Take part in\", \"Test for\", \"Theme\", \"Comparing\"},\n",
    "          \"SYNTHESIS\":{\"Create\", \"Design\", \"Hypothesize\", \"Invent\", \"Develop\", \"Compose\", \"Construct\", \"Integrate\", \"Make\",\n",
    "\t\t\t\t\t   \"Organize\", \"Perform\", \"Plan\", \"Produce\", \"Propose\", \"Rewrite\", \"Arrange\", \"Assemble\", \"Categorize\", \n",
    "\t\t\t\t\t   \"Collect\", \"Combine\", \"Comply\", \"Devise\", \"Explain\", \"Formulate\", \"Generate\", \"Prepare\", \"Rearrange\",\n",
    "\t\t\t\t\t   \"Reconstruct\", \"Relate\", \"Reorganize\", \"Revise\", \"Set up\", \"Summarize\", \"Synthesize\", \"Tell\", \"Write\", \n",
    "\t\t\t\t\t   \"Adapt\", \"Add to\", \"Build\", \"Change\", \"Choose\", \"Combine\", \"Compile\", \"Convert\", \"Delete\", \"Discover\", \n",
    "\t\t\t\t\t   \"Discuss\", \"Elaborate\", \"Estimate\", \"Experiment\", \"Extend\", \"Happen\", \"Hypothesise\", \"Imagine\",\n",
    "\t\t\t\t\t   \"Improve\", \"Innovate\", \"Make up\", \"Maximise\", \"Minimise\", \"Model\", \"Modify\", \"Original\", \"Originate\",\n",
    "\t\t\t\t\t   \"Predict\", \"Reframe\", \"Simplify\", \"Solve\", \"Speculate\", \"Substitute\", \"Suppose\", \"Tabulate\", \"Test\", \n",
    "\t\t\t\t\t   \"Theorise\", \"Think\", \"Transform\", \"Visualise\"},\n",
    "          \"EVALUATION\":{\"Judge\", \"Recommend\", \"Critique\", \"Justify\", \"Appraise\", \"Argue\", \"Assess\", \"Choose\", \"Conclude\", \n",
    "\t\t\t\t\t\t\"Decide\", \"Evaluate\", \"Predict\", \"Prioritize\", \"Prove\", \"Rank\", \"Rate\", \"Select\", \"Attach\", \"Compare\", \n",
    "\t\t\t\t\t\t\"Contrast\", \"Defend\", \"Describe\", \"Discriminate\", \"Estimate\", \"Explain\", \"Interpret\", \"Relate\",\n",
    "\t\t\t\t\t\t\"Summarize\", \"Support\", \"Value\", \"Agree\", \"Award\", \"Bad\", \"Consider\", \"Convince\", \"Criteria\", \n",
    "\t\t\t\t\t\t\"Criticise\", \"Debate\", \"Deduct\", \"Determine\", \"Disprove\", \"Dispute\", \"Effective\", \"Give reasons\", \"Good\",\n",
    "\t\t\t\t\t\t\"Grade\", \"How do we\", \"Know\", \"Importance\", \"Infer\", \"Influence\", \"Mark\", \"Measure\", \"Opinion\", \n",
    "\t\t\t\t\t\t\"Perceive\", \"Persuade\", \"Prioritise\", \"Rule on\", \"Test\", \"Useful\", \"Validate\", \"Why\"}\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xXpKNxJDh2r"
   },
   "source": [
    "**Displaying the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdUWLTsmDh2s",
    "outputId": "f937bcd6-8e5b-4640-d0bd-7a216040cf15"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGv7KfIiDh2u"
   },
   "source": [
    "## Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xehj0ii3Dh2v"
   },
   "outputs": [],
   "source": [
    "# mapping strings to numeric values:\n",
    "def numerical_data():\n",
    "    df['school'] = df['school'].map({'GP': 0, 'MS': 1})\n",
    "    df['gender'] = df['gender'].map({'M': 0, 'F': 1})\n",
    "    df['address'] = df['address'].map({'U': 0, 'R': 1})\n",
    "    df['famsize'] = df['famsize'].map({'LE3': 0, 'GT3': 1})\n",
    "    df['Pstatus'] = df['Pstatus'].map({'T': 0, 'A': 1})\n",
    "    df['Mjob'] = df['Mjob'].map({'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4})\n",
    "    df['Fjob'] = df['Fjob'].map({'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4})\n",
    "    df['reason'] = df['reason'].map({'home': 0, 'reputation': 1, 'course': 2, 'other': 3})\n",
    "    df['guardian'] = df['guardian'].map({'mother': 0, 'father': 1, 'other': 2})\n",
    "    df['schoolsup'] = df['schoolsup'].map({'no': 0, 'yes': 1})\n",
    "    df['famsup'] = df['famsup'].map({'no': 0, 'yes': 1})\n",
    "    df['paid'] = df['paid'].map({'no': 0, 'yes': 1})\n",
    "    df['activities'] = df['activities'].map({'no': 0, 'yes': 1})\n",
    "    df['nursery'] = df['nursery'].map({'no': 0, 'yes': 1})\n",
    "    df['higher'] = df['higher'].map({'no': 0, 'yes': 1})\n",
    "    df['internet'] = df['internet'].map({'no': 0, 'yes': 1})\n",
    "    df['romantic'] = df['romantic'].map({'no': 0, 'yes' : 1})\n",
    "    df['passed'] = df['passed'].map({'no': 0, 'yes': 1})\n",
    "    # reorder dataframe columns :\n",
    "    col = df['passed']\n",
    "    del df['passed']\n",
    "    df['passed'] = col\n",
    "\n",
    "    \n",
    "# feature scaling will allow the algorithm to converge faster, large data will have same scal\n",
    "def feature_scaling(df):\n",
    "    for i in df:\n",
    "        col = df[i]\n",
    "        # let's choose columns that have large values\n",
    "        if(np.max(col)>6):\n",
    "            Max = max(col)\n",
    "            Min = min(col)\n",
    "            mean = np.mean(col)\n",
    "            col  = (col-mean)/(Max)\n",
    "            df[i] = col\n",
    "        elif(np.max(col)<6):\n",
    "            col = (col-np.min(col))\n",
    "            col /= np.max(col)\n",
    "            df[i] = col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkddn4GnDh2w"
   },
   "source": [
    "**digitization of values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IXGtB_O7Dh2w",
    "outputId": "a286cbdd-7079-444c-bd96-6f8b4e4ac7ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  gender  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  \\\n",
       "0         0       1   18        0        1        1     4     4     3     0   \n",
       "1         0       1   17        0        1        0     1     1     3     4   \n",
       "2         0       1   15        0        0        0     1     1     3     4   \n",
       "3         0       1   15        0        1        0     4     2     1     2   \n",
       "4         0       1   16        0        1        0     3     3     4     4   \n",
       "..      ...     ...  ...      ...      ...      ...   ...   ...   ...   ...   \n",
       "390       1       0   20        0        0        1     2     2     2     2   \n",
       "391       1       0   17        0        0        0     3     1     2     2   \n",
       "392       1       0   21        1        1        0     1     1     4     4   \n",
       "393       1       0   18        1        0        0     3     2     2     4   \n",
       "394       1       0   19        0        0        0     1     1     4     3   \n",
       "\n",
       "     ...  internet  romantic  famrel  freetime  goout  Dalc  Walc  health  \\\n",
       "0    ...         0         0       4         3      4     1     1       3   \n",
       "1    ...         1         0       5         3      3     1     1       3   \n",
       "2    ...         1         0       4         3      2     2     3       3   \n",
       "3    ...         1         1       3         2      2     1     1       5   \n",
       "4    ...         0         0       4         3      2     1     2       5   \n",
       "..   ...       ...       ...     ...       ...    ...   ...   ...     ...   \n",
       "390  ...         0         0       5         5      4     4     5       4   \n",
       "391  ...         1         0       2         4      5     3     4       2   \n",
       "392  ...         0         0       5         5      3     3     3       3   \n",
       "393  ...         1         0       4         4      1     3     4       5   \n",
       "394  ...         1         0       3         2      3     3     3       5   \n",
       "\n",
       "     absences  passed  \n",
       "0           6       0  \n",
       "1           4       0  \n",
       "2          10       1  \n",
       "3           2       1  \n",
       "4           4       1  \n",
       "..        ...     ...  \n",
       "390        11       0  \n",
       "391         3       1  \n",
       "392         3       0  \n",
       "393         0       1  \n",
       "394         5       0  \n",
       "\n",
       "[395 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All values in numerical after calling numerical_data() function\n",
    "numerical_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsD7_n0aDh2x"
   },
   "source": [
    "    - Now, all the values in the dataset are numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf7StmhNDh2x"
   },
   "source": [
    "**Features scalling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-WQM7VDLDh2y",
    "outputId": "d59f82f7-29d9-4810-9518-7d8732e17409"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.022785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.077100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.057215</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.077100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.049451</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.022785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.070549</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.036118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.036118</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.076118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.009451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  gender       age  address  famsize  Pstatus  Medu  Fedu  Mjob  \\\n",
       "0       0.0     1.0  0.059264      0.0      1.0      1.0  1.00  1.00  0.75   \n",
       "1       0.0     1.0  0.013809      0.0      1.0      0.0  0.25  0.25  0.75   \n",
       "2       0.0     1.0 -0.077100      0.0      0.0      0.0  0.25  0.25  0.75   \n",
       "3       0.0     1.0 -0.077100      0.0      1.0      0.0  1.00  0.50  0.25   \n",
       "4       0.0     1.0 -0.031646      0.0      1.0      0.0  0.75  0.75  1.00   \n",
       "..      ...     ...       ...      ...      ...      ...   ...   ...   ...   \n",
       "390     1.0     0.0  0.150173      0.0      0.0      1.0  0.50  0.50  0.50   \n",
       "391     1.0     0.0  0.013809      0.0      0.0      0.0  0.75  0.25  0.50   \n",
       "392     1.0     0.0  0.195627      1.0      1.0      0.0  0.25  0.25  1.00   \n",
       "393     1.0     0.0  0.059264      1.0      0.0      0.0  0.75  0.50  0.50   \n",
       "394     1.0     0.0  0.104718      0.0      0.0      0.0  0.25  0.25  1.00   \n",
       "\n",
       "     Fjob  ...  internet  romantic  famrel  freetime  goout  Dalc  Walc  \\\n",
       "0    0.00  ...       0.0       0.0    0.75      0.50   0.75  0.00  0.00   \n",
       "1    1.00  ...       1.0       0.0    1.00      0.50   0.50  0.00  0.00   \n",
       "2    1.00  ...       1.0       0.0    0.75      0.50   0.25  0.25  0.50   \n",
       "3    0.50  ...       1.0       1.0    0.50      0.25   0.25  0.00  0.00   \n",
       "4    1.00  ...       0.0       0.0    0.75      0.50   0.25  0.00  0.25   \n",
       "..    ...  ...       ...       ...     ...       ...    ...   ...   ...   \n",
       "390  0.50  ...       0.0       0.0    1.00      1.00   0.75  0.75  1.00   \n",
       "391  0.50  ...       1.0       0.0    0.25      0.75   1.00  0.50  0.75   \n",
       "392  1.00  ...       0.0       0.0    1.00      1.00   0.50  0.50  0.50   \n",
       "393  1.00  ...       1.0       0.0    0.75      0.75   0.00  0.50  0.75   \n",
       "394  0.75  ...       1.0       0.0    0.50      0.25   0.50  0.50  0.50   \n",
       "\n",
       "     health  absences  passed  \n",
       "0      0.50  0.003882     0.0  \n",
       "1      0.50 -0.022785     0.0  \n",
       "2      0.50  0.057215     1.0  \n",
       "3      1.00 -0.049451     1.0  \n",
       "4      1.00 -0.022785     1.0  \n",
       "..      ...       ...     ...  \n",
       "390    0.75  0.070549     0.0  \n",
       "391    0.25 -0.036118     1.0  \n",
       "392    0.50 -0.036118     0.0  \n",
       "393    1.00 -0.076118     1.0  \n",
       "394    1.00 -0.009451     0.0  \n",
       "\n",
       "[395 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scal our features\n",
    "feature_scaling(df)\n",
    "\n",
    "# Now we are ready for models training\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smPmoAl7Dh2y"
   },
   "source": [
    "# Data visualisation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvneVCTUDh2z"
   },
   "source": [
    "## 1) data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RtgSCBolDh2z",
    "outputId": "0f839c7f-9887-4c09-d603-00cdea55946a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KPYTV-OQDh2z",
    "outputId": "2f4c95b7-4c7f-4b06-b1c0-9ec8add62875"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().shape # their is no null value \"fortunately:)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PhesJfHDh20",
    "outputId": "316a318f-d49b-4b89-8f49-9ad5a7d8fadd"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FTISg82RDh20"
   },
   "outputs": [],
   "source": [
    "features=['school', 'gender', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "       'Walc', 'health', 'absences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoyMzEJcDh21"
   },
   "source": [
    "## 2)features visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PdEAVEgRDh21",
    "outputId": "10ca806e-a9ab-4b6e-aa21-d5a662968b45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    265\n",
       "no     130\n",
       "Name: passed, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot of student status\n",
    "dfv['passed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p2DArl3lDh21",
    "outputId": "f9f3060d-2857-4c7d-b6db-b74486a29719"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = 'student pass the final exam ', 'student fail the final exam'\n",
    "sizes = [265, 130]\n",
    "colors=['lightskyblue','yellow']\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes,  labels=labels, autopct='%1.1f%%',colors=colors,\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7Ssp8paDh22"
   },
   "source": [
    "Likely most of student passed the exam ,our goal is to decrease the student failure as max as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YKpjgdkDh22"
   },
   "source": [
    " ### a)Correlation heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPfQC12IDh22"
   },
   "source": [
    "   #### -a.1) general hetmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1QYLgh5Dh22",
    "outputId": "0bf077cd-a826-4f4e-96ad-7cf89c3f6f6d"
   },
   "outputs": [],
   "source": [
    "# see correlation between variables through a correlation heatmap\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.heatmap(corr, annot=True, cmap=\"Reds\")\n",
    "plt.title('Correlation Heatmap', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpiztrehDh23"
   },
   "source": [
    "#### a.2)correlation between student status and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQ-vk9WYDh23",
    "outputId": "22846a68-617e-43ce-f19b-0f210019c007"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(df.corr()[['passed']].sort_values(by='passed', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with the status of student', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3a60vK_Dh24"
   },
   "source": [
    "### b) Distribution plot\n",
    "\n",
    "In this step let's look deeper into each features and make a final summary for best social,demographic and school conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IQvcq2RDh24",
    "outputId": "eae25be3-a96b-4778-fd19-fc0331f1770f"
   },
   "outputs": [],
   "source": [
    "df[\"goout\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjK0dkzODh25",
    "outputId": "d903a5ea-8d1a-4bd0-f1b7-edc70066b94a"
   },
   "outputs": [],
   "source": [
    "# going out\n",
    "perc = (lambda col: col/col.sum())\n",
    "index = [0,1]\n",
    "out_tab = pd.crosstab(index=df.passed, columns=df.goout)\n",
    "out_perc = out_tab.apply(perc).reindex(index)\n",
    "out_perc.plot.bar(colormap=\"mako_r\", fontsize=16, figsize=(14,6))\n",
    "plt.title('student status  By Frequency of Going Out', fontsize=20)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)\n",
    "plt.xlabel('Student status', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwCU4CRXDh25"
   },
   "source": [
    "-C1: it seems that most of people who passed the exam had less hour of going out ,as a conclusion we should limit the hour of going out with friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfoT8u02Dh25"
   },
   "source": [
    "-C2:Most of people whow passed the exam had no romantic relation ,sow no relation could be a good choice for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmvtUWv3Dh25"
   },
   "source": [
    "#### b.3)Student status by  mother job and mother education:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61EvluqRDh26",
    "outputId": "1115f2dd-8593-482b-c103-faaf71e3b7b7"
   },
   "outputs": [],
   "source": [
    "# 1) mother job \n",
    "# Mjob distribution\n",
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'Mjob', data=dfv, order=['teacher','health','services','at_home','other'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"Mother Job\")\n",
    "figure.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hz0sP1YeDh26",
    "outputId": "98d12231-d3a2-4851-e405-267ce9184676"
   },
   "outputs": [],
   "source": [
    "mjob_tab1 = pd.crosstab(index=df.passed, columns=df.Mjob)\n",
    "mjob_tab = np.log(mjob_tab1)\n",
    "mjob_perc = mjob_tab.apply(perc).reindex(index)\n",
    "plt.figure()\n",
    "mjob_perc.plot.bar(colormap=\"mako_r\", fontsize=16, figsize=(8,8))\n",
    "plt.title('Student status By mother JOB', fontsize=20)\n",
    "plt.ylabel('Percentage of Logarithm Student Counts ', fontsize=16)\n",
    "plt.xlabel('Student status', fontsize=16)\n",
    "plt.show()\n",
    "#'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKKGDE9mDh27",
    "outputId": "dd1d7745-3b79-4ea8-ab16-8ed50a14d1e9"
   },
   "outputs": [],
   "source": [
    "#Mother education:\n",
    "good = df.loc[df.passed==1]\n",
    "poor=df.loc[df.passed==0]\n",
    "good['good_student_mother_education'] = good.Medu\n",
    "poor['poor_student_mother_education'] = poor.Medu\n",
    "plt.figure(figsize=(6,4))\n",
    "p=sns.kdeplot(good['good_student_mother_education'], shade=True, color=\"r\")#good_student in red\n",
    "p=sns.kdeplot(poor['poor_student_mother_education'], shade=True, color=\"b\")#poor_student in blue\n",
    "plt.xlabel('Mother Education Level', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hTvFdM0Dh27"
   },
   "source": [
    "C4:Mother height education had good impact in student status.If we look into the second heatmap previousely it seems that Medu is more impactfful than Fedu sow if you are woman study hard ,if you are man marry a woman with higher education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHnwgzTkDh27"
   },
   "source": [
    "\n",
    "#### b.4)Student status by deseire to take heigher education:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s--J8H_qDh27",
    "outputId": "1825b466-1f93-4936-aceb-0244ac499dac"
   },
   "outputs": [],
   "source": [
    "higher_tab = pd.crosstab(index=df.passed, columns=df.higher)\n",
    "higher_perc = higher_tab.apply(perc).reindex(index)\n",
    "higher_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('Final Grade By Desire to Receive Higher Education', fontsize=20)\n",
    "plt.xlabel('Final Grade', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVz4pSbiDh28"
   },
   "source": [
    "C4:Most of people who passed the exam want to take heigher education sow it could be a good idea to encourage your kids or students to take heigher education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bLCEl_rDh28"
   },
   "source": [
    "#### b.5)Student status by age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e4CZ7u1Dh28",
    "outputId": "8cee3f2f-eeb8-4fea-c440-842aebb8c75b"
   },
   "outputs": [],
   "source": [
    "#impact of age\n",
    "higher_tab = pd.crosstab(index=df.passed, columns=df.age)\n",
    "higher_perc = higher_tab.apply(perc).reindex(index)\n",
    "higher_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('Student status  By age', fontsize=20)\n",
    "plt.xlabel('Student status', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kUZRQKBDh28"
   },
   "source": [
    "C5:Age also play an importent role in student sucess, most of people who passed the exam had early age 15, and most people who failed the exam had an age of 22 .As a conclusion it could be better to go to school in early age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJyEQnVuDh29"
   },
   "source": [
    "#### b.6) Student status by failures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgjF7m7JDh29"
   },
   "outputs": [],
   "source": [
    "#impact of failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7HkiEOUDh29",
    "outputId": "6d1938c7-7e72-4e46-f328-8cac948a7f30"
   },
   "outputs": [],
   "source": [
    "fail_tab = pd.crosstab(index=df.passed, columns=df.failures)\n",
    "fail_perc = fail_tab.apply(perc).reindex(index)\n",
    "fail_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('student status By failures', fontsize=20)\n",
    "plt.xlabel('Final Grade', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMg213W_Dh29"
   },
   "source": [
    "C6:most of people who passed the exam had 0failures sow it could be a good choice to study hard and pass all the grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta6ras2DDh2-"
   },
   "source": [
    "#### b.7) Student status by area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axkAy1KDDh2-",
    "outputId": "1ff53d67-c20a-4546-e6d9-fe298580721b"
   },
   "outputs": [],
   "source": [
    "#first let's see the destribution of students who live in urban or rural area\n",
    "f, fx = plt.subplots()\n",
    "figure = sns.countplot(x = 'address', data=dfv, order=['U','R'])\n",
    "fx = fx.set(ylabel=\"Count\", xlabel=\"address\")\n",
    "figure.grid(False)\n",
    "plt.title('Address Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tx07KZ_IDh2-",
    "outputId": "9c2c0a49-ad32-424a-caaf-4635cb12a4b3"
   },
   "outputs": [],
   "source": [
    "ad_tab1 = pd.crosstab(index=df.passed, columns=df.address)\n",
    "ad_tab = np.log(ad_tab1)\n",
    "ad_perc = ad_tab.apply(perc).reindex(index)\n",
    "ad_perc.plot.bar(colormap=\"RdYlGn_r\", fontsize=16, figsize=(8,6))\n",
    "plt.title('student status By Living Area', fontsize=20)\n",
    "plt.ylabel('Percentage of Logarithm Student#', fontsize=16)\n",
    "plt.xlabel('Student status', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23yAMn9CDh2_"
   },
   "source": [
    "C7:Area doesn't had an impact on student performance even people with good results live in contry side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdEcNSykDh2_"
   },
   "source": [
    "#### b.8) Student status by alchool consumption :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5K3AhU5EDh2_",
    "outputId": "3c9a6247-46c6-450d-de0f-210d691ee27f"
   },
   "outputs": [],
   "source": [
    "#impact of weekend alcohol consumption in student performance\n",
    "alc_tab = pd.crosstab(index=df.passed, columns=df.Walc)\n",
    "alc_perc = alc_tab.apply(perc).reindex(index)\n",
    "alc_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('student status By alchol consumption', fontsize=20)\n",
    "plt.xlabel('Student status', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRkN1z33Dh2_",
    "outputId": "bf8baf3b-4597-422c-a06a-61092885fff9"
   },
   "outputs": [],
   "source": [
    "# weekend alcohol consumption\n",
    "# create good student dataframe\n",
    "good = df.loc[df.passed == 1]\n",
    "good['good_alcohol_usage']=good.Walc\n",
    "# create poor student dataframe\n",
    "poor = df.loc[df.passed == 0]\n",
    "poor['poor_alcohol_usage']=poor.Walc\n",
    "plt.figure(figsize=(10,6))\n",
    "p1=sns.kdeplot(good['good_alcohol_usage'], shade=True, color=\"r\")\n",
    "p1=sns.kdeplot(poor['poor_alcohol_usage'], shade=True, color=\"b\")\n",
    "plt.title('Good Performance vs. Poor Performance Student Alcohol Consumption', fontsize=20)\n",
    "plt.ylabel('Density', fontsize=16)\n",
    "plt.xlabel('Level of Alcohol Consumption', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmBv2t2LDh3A"
   },
   "source": [
    "For weekely alchool consumption it doesn't have an strong impact on student performance .Even people with low consumption had low grad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD8jZ99yDh3A"
   },
   "source": [
    "#### b.9) Student status by internet accessibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RgapHGcDh3A",
    "outputId": "582ced04-ff0f-4190-93b7-fe5dc28f01d4"
   },
   "outputs": [],
   "source": [
    "alc_tab = pd.crosstab(index=df.passed, columns=df.internet)\n",
    "alc_perc = alc_tab.apply(perc).reindex(index)\n",
    "alc_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('student status By internet accessibility', fontsize=20)\n",
    "plt.xlabel('Student status', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCSA0q8MDh3A"
   },
   "source": [
    "C9:Most of people who passed the exam had the accessibility to internet ,sow we should provide a fair materials's education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTi__vkvDh3B"
   },
   "source": [
    "#### b.10) Student status by wekelly Study time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BV1pMr1dDh3B",
    "outputId": "73f2f31c-b0e7-411d-ee93-8c9a73f651f8"
   },
   "outputs": [],
   "source": [
    "stu_tab = pd.crosstab(index=df.passed, columns=df.studytime)\n",
    "stu_perc = stu_tab.apply(perc).reindex(index)\n",
    "stu_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('student status By study time', fontsize=20)\n",
    "plt.xlabel('Student status', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KFyeWBgDh3B"
   },
   "source": [
    "C10:Most of people who passed the exam study 5-10 hours weekely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q77ninj_Dh3B"
   },
   "source": [
    "#### b.11)Student status by health:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18tTHG-WDh3C",
    "outputId": "5f7d8984-77b4-4218-d01d-89afe1533861"
   },
   "outputs": [],
   "source": [
    "he_tab = pd.crosstab(index=df.passed, columns=df.health)\n",
    "he_perc = he_tab.apply(perc).reindex(index)\n",
    "he_perc.plot.bar(colormap=\"Dark2_r\", figsize=(14,6), fontsize=16)\n",
    "plt.title('student status By health', fontsize=20)\n",
    "plt.xlabel('Student status', fontsize=16)\n",
    "plt.ylabel('Percentage of Student', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2yyhr2VDh3C"
   },
   "source": [
    "C11:most of student who fails the exam don't have a good health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_95VP4OUDh3C"
   },
   "outputs": [],
   "source": [
    "#making summary for good condition to reach heigh academic potentials:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Eyv28jbDh3C"
   },
   "source": [
    "# Logistic regression  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4J5jFTUwDh3C"
   },
   "source": [
    "# 1-Logistic Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xo2uDLZYDh3D"
   },
   "outputs": [],
   "source": [
    "# split data train 70 % and test 30 %\n",
    "\n",
    "data = df.to_numpy()\n",
    "n = data.shape[1]\n",
    "x = data[:,0:n-1]\n",
    "y = data[:,n-1]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "\n",
    "# Once our data is split, we can forget about x_test and y_test until we define our model.\n",
    "#x_train and y_train are the samples we will use to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2UdjyG-Dh3D"
   },
   "outputs": [],
   "source": [
    "# let's create a model and train it \n",
    "\n",
    "logisticRegr = LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj7N7XvEDh3D",
    "outputId": "eaa5eee9-f450-42b8-d501-bfa95302481a"
   },
   "outputs": [],
   "source": [
    "#and now let's do the training\n",
    "\n",
    "logisticRegr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9CXcxHKDh3D"
   },
   "outputs": [],
   "source": [
    "#The model is now trained and ready to make predictions :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1M0orXYDh3E",
    "outputId": "e88ade5e-b7d0-423d-866d-ef451e0eb025"
   },
   "outputs": [],
   "source": [
    "y_pred=logisticRegr.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9fIzwzJDh3E"
   },
   "source": [
    "# 2-Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyjZOb03Dh3E"
   },
   "source": [
    "In order to evaluate our model , we will first calculate the accuracy of the model , visualize the confusion matrix, and then plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpH5EmfdDh3E",
    "outputId": "ab00ed17-1195-477f-cb25-b9c28aeebd54"
   },
   "outputs": [],
   "source": [
    "#let's have a look at the accuracy of the model\n",
    "\n",
    "Sctest=logisticRegr.score(x_test,y_test)\n",
    "Sctrain=logisticRegr.score(x_train,y_train)\n",
    "\n",
    "print('#Accuracy test is: ',Sctest)\n",
    "print('#Accuracy train is: ',Sctrain)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('\\n#f1 score is: ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCjMwNB0Dh3E"
   },
   "source": [
    "#\n",
    "We got two values of the accuracy, one obtained with the training set and other with the test set.\n",
    "\n",
    "It might be a good idea to compare the two, as a situation where the training set accuracy is much higher might indicate overfitting. The test set accuracy is more relevant for evaluating the performance on unseen data since it’s not biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q74tKgwYDh3F",
    "outputId": "8b9a7ae9-5485-4da2-baa6-b1d851954278"
   },
   "outputs": [],
   "source": [
    "#let's have a look at the accuracy of the model\n",
    "\n",
    "Sctest=logisticRegr.score(x_test,y_test)\n",
    "Sctrain=logisticRegr.score(x_train,y_train)\n",
    "\n",
    "print('Accuracy test is: ',Sctest)\n",
    "print('Accuracy train is: ',Sctrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyF4gLlADh3F",
    "outputId": "0a913483-307e-45c7-bd80-5f70c8211b22"
   },
   "outputs": [],
   "source": [
    "#now, we can get the confusion matrix with confusion_matrix():\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdEc8EdjDh3F",
    "outputId": "7ce49c82-9086-4806-ea1c-99c058a4b2a2"
   },
   "outputs": [],
   "source": [
    "#let's visualize the confusion matrix:\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkXsEJqiDh3F",
    "outputId": "ef57b887-c22b-4117-e3d0-c14d7d046725"
   },
   "outputs": [],
   "source": [
    "#import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPrjbPlwDh3G"
   },
   "source": [
    "ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DdkaY45zDh3G",
    "outputId": "fab7630c-e5d7-47e0-8f6f-200a14ebc4e5"
   },
   "outputs": [],
   "source": [
    "#ploting the roc_curve\n",
    "\n",
    "fpositif, tpositif, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.plot(fpositif,tpositif, label='LogisticRegr')\n",
    "plt.xlabel('false positif')\n",
    "plt.ylabel('true positif')\n",
    "plt.title('LogisticRegr ROC curve')\n",
    "p=plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpTxB4VlDh3G"
   },
   "source": [
    "# 3-improving model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UhDlrRJDh3G",
    "outputId": "0a6551d0-901c-46b0-be95-81305f1600f4"
   },
   "outputs": [],
   "source": [
    "max_iteration = 0\n",
    "maxF1 = 0\n",
    "maxAccuracy = 0\n",
    "optimal_state = 0\n",
    "import random\n",
    "for k in range(max_iteration):\n",
    "    print ('Iteration :'+str(k)+', Current accuracy: '+str(maxAccuracy)+ ', Current f1 : '+str(maxF1), end=\"\\r\")\n",
    "    split_state = np.random.randint(1,100000000)-1\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=split_state)\n",
    "    logisticRegr = LogisticRegression(C=1)\n",
    "    logisticRegr.fit(x_train,y_train)\n",
    "    y_pred=logisticRegr.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    \n",
    "    if (accuracy>maxAccuracy and f1>maxF1):\n",
    "        maxF1 = f1 \n",
    "        maxAccuracy = accuracy\n",
    "        optimal_state = split_state\n",
    "    \n",
    "   \n",
    "optimal_state = 85491961\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=optimal_state)\n",
    "logisticRegr = LogisticRegression(C=1)\n",
    "logisticRegr.fit(x_train,y_train)\n",
    "y_pred=logisticRegr.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('\\n\\n\\n*Accuracy is: '+str(accuracy)+'\\n*f1 score is: ',f1)\n",
    "\n",
    "yt_lg,yp_lg = y_test,y_pred\n",
    "#ploting the roc_curve\n",
    "\n",
    "print ( '\\n\\n *the ROC curve: ')\n",
    "\n",
    "fpositif, tpositif, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.plot(fpositif,tpositif, label='LogisticRegr')\n",
    "plt.xlabel('false positif')\n",
    "plt.ylabel('true positif')\n",
    "plt.title('LogisticRegr ROC curve')\n",
    "p=plt.show()\n",
    "\n",
    "\n",
    "#visualizig the confusion matrix:\n",
    "\n",
    "print (' *the confusion matrix ')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oAUrjGhDh3H"
   },
   "source": [
    "# k-nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOgRXx_CDh3H"
   },
   "outputs": [],
   "source": [
    "#define data\n",
    "y=df.passed\n",
    "target=[\"passed\"]\n",
    "x = df.drop(target,axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ir6-PL34Dh3H",
    "outputId": "6dc45086-49ff-43c3-d0b1-c1bb6f01c1ce"
   },
   "outputs": [],
   "source": [
    "max_iteration = 0\n",
    "maxF1 = 0\n",
    "maxAccuracy = 0\n",
    "optimal_state = 0\n",
    "for k in range(max_iteration):\n",
    "    print ('Iteration :'+str(k)+', Current accuracy: '+str(maxAccuracy)+ ', Current f1 : '+str(maxF1), end=\"\\r\")\n",
    "    split_state = np.random.randint(1,100000000)-1\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=split_state)\n",
    "    KNN = KNeighborsClassifier()\n",
    "    KNN.fit(x_train,y_train)\n",
    "    y_pred=KNN.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    \n",
    "    if (accuracy>maxAccuracy and f1>maxF1):\n",
    "        maxF1 = f1 \n",
    "        maxAccuracy = accuracy\n",
    "        optimal_state = split_state\n",
    "    \n",
    "optimal_state = 71027464\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=optimal_state)\n",
    "KNN= KNeighborsClassifier()\n",
    "KNN.fit(x_train,y_train)\n",
    "y_pred=KNN.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('\\n\\n\\n*Accuracy is: '+str(accuracy)+'\\n*f1 score is: ',f1)\n",
    "\n",
    "print ('random_state is ',optimal_state)\n",
    "\n",
    "\n",
    "#ploting the roc_curve\n",
    "\n",
    "print ( '\\n\\n *the ROC curve: ')\n",
    "\n",
    "fpositif, tpositif, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.plot(fpositif,tpositif, label='knn')\n",
    "plt.xlabel('false positif')\n",
    "plt.ylabel('true positif')\n",
    "plt.title('KNN ROC curve')\n",
    "p=plt.show()\n",
    "\n",
    "yt_knn,yp_knn= y_test,y_pred\n",
    "#visualizig the confusion matrix:\n",
    "\n",
    "print (' *the confusion matrix ')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_-DzDBcDh3H",
    "outputId": "3e866ae4-0877-4b06-e3f3-e6243353fbc8"
   },
   "outputs": [],
   "source": [
    "#Setup arrays to store training and test accuracies\n",
    "neighbors= np.arange(1,20)\n",
    "train_accuracy =np.empty(19)\n",
    "test_accuracy = np.empty(19)\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #Fit the model\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(x_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = knn.score(x_test, y_test) \n",
    "    \n",
    "#  Plotting the curv\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TX1q6TP7Dh3I"
   },
   "source": [
    "**1) best k for training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmh_4DnjDh3I",
    "outputId": "82f5eccb-f019-4de0-8bfd-9a592ee31240"
   },
   "outputs": [],
   "source": [
    "#In case of classifier like knn the parameter to be tuned is n_neighbors \n",
    "param_grid = {'n_neighbors':np.arange(1,20)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
    "knn_cv.fit(x_train,y_train)\n",
    "#best score\\n\",\n",
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYlbHTjWDh3I",
    "outputId": "f4621f57-b8b0-41e9-c61e-914286e18d61"
   },
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-Kjzu62Dh3J"
   },
   "source": [
    "**2) best k for testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CQ7BYtIDh3J",
    "outputId": "f20fcaf1-738d-4edf-8fb1-d5965404f762"
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors':np.arange(1,20)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
    "knn_cv.fit(x_test,y_test)\n",
    "#best score\\n\",\n",
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIO44ioVDh3J",
    "outputId": "7609a4dc-1fe7-4895-a74d-5e78653277f9"
   },
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FSFaKEXDh3J"
   },
   "source": [
    "**2) best k for all the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLaRX2OTDh3K",
    "outputId": "f5356d0c-71c9-4c01-ca04-b702506397e8"
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors':np.arange(1,20)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
    "knn_cv.fit(x,y)\n",
    "#best score\\n\",\n",
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR8-0h6hDh3K",
    "outputId": "872465f8-758f-41b1-969c-1840aebb913f"
   },
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FVsdKXnDh3K"
   },
   "source": [
    "#Method 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BQXtGR0Dh3K"
   },
   "source": [
    "In this method we are going to fixe the value of k to k= 17 and  search for Best metric(distance)  based on time and acc ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY-xiF3oDh3K",
    "outputId": "87bda968-d5a5-4371-962f-d5438299d1ca"
   },
   "outputs": [],
   "source": [
    "params = {\"n_neighbors\":[7,19] , \"metric\":[\"euclidean\", \"manhattan\", \"chebyshev\"]}\n",
    "acc = {}\n",
    "\n",
    "for m in params[\"metric\"]:\n",
    "    acc[m] = []\n",
    "    for k in params[\"n_neighbors\"]:\n",
    "        print(\"Model_{} metric: {}, n_neighbors: {}\".format(i, m, k))\n",
    "        i += 1\n",
    "        t = time()\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=m)\n",
    "        knn.fit(x_train,y_train)\n",
    "        pred = knn.predict(x_test)\n",
    "        print(\"Time: \", time() - t)\n",
    "        acc[m].append(accuracy_score(y_test, y_pred))\n",
    "        print(\"Acc: \", acc[m][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLb-SqnDh3L"
   },
   "source": [
    "As  We can see  the  metrics or distances gives the same accuracy  but time is different,the optimal_time for k=7 is   0.019012451171875 . This choice  gives heigh Acc=78% with less time consuming compared to other distances the wining distance is **chebyshev**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6XAz5ymDh3L"
   },
   "source": [
    "<h5 style='color:blue;font-family:cursive;font-size:4.5mm'>third step: </h5>\n",
    "\n",
    "In this method we are going to commbine **knn hyperparameters tuning** (second step) and  **the  optimal random state**(first step) to get high accuracy\n",
    "\n",
    "### B)Final model implementation\n",
    "\n",
    "As we discover in privious section the best parameters to implement knn algorithme are:\n",
    "   - K=7\n",
    "   - metric=chebyshev-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5e9AOSuDh3L",
    "outputId": "ca8e5bd6-a6ef-4f3e-b1e3-a5c50a91032c"
   },
   "outputs": [],
   "source": [
    "max_iteration = 0\n",
    "maxF1 = 0\n",
    "maxAccuracy = 0\n",
    "optimal_state = 0\n",
    "f1 = 0\n",
    "accuracy = 0\n",
    "True60 = False\n",
    "for k in range(max_iteration):\n",
    "    print ('Iteration :'+str(k)+', Current accuracy: '+str(maxAccuracy)+ ', Current f1 : '+str(maxF1), end=\"\\r\")\n",
    "    split_state = np.random.randint(1,100000000)-1\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=split_state)\n",
    "    KNN = KNeighborsClassifier(n_neighbors=7,metric='chebyshev')\n",
    "    KNN.fit(x_train,y_train)\n",
    "    y_pred=KNN.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    \n",
    "    if accuracy>maxAccuracy and f1>=0.5:\n",
    "        maxF1 = f1 \n",
    "        maxAccuracy = accuracy\n",
    "        optimal_state = split_state\n",
    "        if maxAccuracy>79:\n",
    "            break\n",
    "    \n",
    "optimal_state = 29300362         \n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=optimal_state)\n",
    "KNN_f= KNeighborsClassifier(n_neighbors=7,metric='chebyshev')\n",
    "KNN_f.fit(x_train,y_train)\n",
    "y_pred=KNN_f.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('\\n\\n\\n*Accuracy is: '+str(accuracy)+'\\n*f1 score is: ',f1)\n",
    "\n",
    "print ('random_state is ',optimal_state)\n",
    "\n",
    "yt_knn,yp_knn= y_test,y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEaDuKLlDh3M"
   },
   "source": [
    "**-As we can see if we combine the best knn parameters and optimal state the acquracy improve from 78% to 79%**\n",
    "It's clear that hyperparameters_tuning increase the result but most impactfull parameters are random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8fvQA5SDh3M"
   },
   "source": [
    "1)**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV48TCrJDh3M",
    "outputId": "56bc0c28-ae0a-4935-8004-99423e7be975"
   },
   "outputs": [],
   "source": [
    "ac = accuracy_score(yt_knn,yp_knn)\n",
    "print('Accuracy is: ',ac)\n",
    "cm= confusion_matrix(yt_knn,yp_knn)\n",
    "sns.heatmap(cm,annot=True)\n",
    "yt_knn,yp_knn = y_test,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A0A2T2bDh3M"
   },
   "source": [
    "2)**classification_report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sK0lPwrfDh3M",
    "outputId": "90f8879f-63cc-4477-dd7f-4210630b254e"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4uLrhUcDh3N",
    "outputId": "eff2aefa-3b9d-4eb9-81a4-b266c30b30a4"
   },
   "outputs": [],
   "source": [
    "#ploting the roc_curve\n",
    "\n",
    "print ( ' the ROC curve: ')\n",
    "\n",
    "fpositif, tpositif, thresholds = roc_curve(y_test, y_pred)\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.plot(fpositif,tpositif, label='final knn model')\n",
    "plt.xlabel('false positif')\n",
    "plt.ylabel('true positif')\n",
    "plt.title('knn_f ROC curve')\n",
    "p=plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFIMQDrXDh3N"
   },
   "source": [
    "<h5 style='color:red;font-family:cursive;font-size:4.5mm'> 4 Conclusion :</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je5UFYCJDh3N"
   },
   "source": [
    "# Support vector machine \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PRBgSosDh3N"
   },
   "source": [
    "- We will explain each of these functions very well inside the following cell itself :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JiGWwtOyDh3O"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Show results of every model\n",
    "\n",
    "def showResults(accuracy, trainingTime, y_pred,model):\n",
    "    \n",
    "    print('------------------------------------------------Results :',model,'-------------------------------------------------')\n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    print('\\n The ROC curve is :\\n')\n",
    "    fig, _ = plt.subplots()\n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y_pred)\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label=model)\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    plt.legend()\n",
    "    fig.suptitle('ROC curve: '+str(model))\n",
    "    plt.show()\n",
    "    \n",
    "    print('----------------------------------------------')\n",
    "    print('The model  accuracy:', round(accuracy),'%')\n",
    "    print('----------------------------------------------')\n",
    "    print('The training time is: ',trainingTime)\n",
    "    print('----------------------------------------------')\n",
    "    print('The f1 score is :',round(100*f1_score(y_test, y_pred, average='macro'))/100)\n",
    "    print('----------------------------------------------')\n",
    "    print('The roc_auc_score is :',round(100*roc_auc_score(y_test, y_pred))/100)\n",
    "    print('----------------------------------------------')\n",
    "    print('The confusion matrix is :\\n')\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(confusionMatrix,annot=True)\n",
    "\n",
    "\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Hyperparameter Tuning :\n",
    "# C, degree and gamma are the parameters that are used in SVM classffier 'svc(C=..,..),svc(C,degree=..)',svc(C,gamma=..)\n",
    "# The following functions will return those values that minimize the error on (X_val,y_val) set\n",
    "# So this (X_val,y_val) set will be used to get the optimal SVM parameters before evaluating the model on the test set\n",
    "\n",
    "\n",
    "# Optimal C \n",
    "def optimal_C_value():\n",
    "    Ci = np.array(( 0.0001,0.001,0.01,0.05,0.1,4,10,40,100))\n",
    "    minError = float('Inf')\n",
    "    optimal_C = float('Inf')\n",
    "\n",
    "    for c in Ci:\n",
    "        clf = SVC(C=c,kernel='linear')\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_val)\n",
    "        error = np.mean(np.double(predictions != y_val))\n",
    "        if error < minError:\n",
    "            minError = error\n",
    "            optimal_C = c\n",
    "    return optimal_C\n",
    "\n",
    "\n",
    "# Optimal C and the degree of the polynomial\n",
    "def optimal_C_d_values():\n",
    "    Ci = np.array(( 0.0001,0.001,0.01,0.05,0.1,4,10,40,100))\n",
    "    Di = np.array(( 2, 5, 10, 15, 20, 25, 30))\n",
    "    minError = float('Inf')\n",
    "    optimal_C = float('Inf')\n",
    "    optimal_d = float('Inf')\n",
    "\n",
    "    for d in Di:\n",
    "        for c in Ci:\n",
    "            clf = SVC(C=c,kernel='poly', degree=d)\n",
    "            clf.fit(X_train, y_train)\n",
    "            predictions = clf.predict(X_val)\n",
    "            error = np.mean(np.double(predictions != y_val))\n",
    "            if error < minError:\n",
    "                minError = error\n",
    "                optimal_C = c\n",
    "                optimal_d = d\n",
    "    return optimal_C,optimal_d\n",
    "\n",
    "\n",
    "# Optimal C and gamma\n",
    "def optimal_C_gamma_values():\n",
    "    Ci = np.array(( 0.0001,0.001,0.01,0.05,0.1,4,10,40,100))\n",
    "    Gi = np.array(( 0.000001,0.00001,0.01,1,2,3,5,20,70,100,500,1000))\n",
    "    minError = float('Inf')\n",
    "    optimal_C = float('Inf')\n",
    "    optimal_g = float('Inf')\n",
    "\n",
    "    for g in Gi:\n",
    "        for c in Ci:\n",
    "            clf = SVC(C=c,kernel='rbf', gamma=g)\n",
    "            clf.fit(X_train, y_train)\n",
    "            predictions = clf.predict(X_val)\n",
    "            error = np.mean(np.double(predictions != y_val))\n",
    "            if error < minError:\n",
    "                minError = error\n",
    "                optimal_C = c\n",
    "                optimal_g = g\n",
    "    return optimal_C,optimal_g\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Compare the three kernels\n",
    "\n",
    "\n",
    "def compare_kernels():\n",
    "    X_train1,X_val1,X_test1,y_train1,y_val1,y_test1 = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state1)\n",
    "    X_train2,X_val2,X_test2,y_train2,y_val2,y_test2 = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state2)\n",
    "    X_train3,X_val3,X_test3,y_train3,y_val3,y_test3 = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state3)\n",
    "    print('------------------------------------------------ Comparison -----------------------------------------------------')\n",
    "    print('\\n')\n",
    "    f11 = \"{:.2f}\".format(f1_score(y_test1, y_linear, average='macro'))\n",
    "    f22 = \"{:.2f}\".format(f1_score(y_test2, y_poly, average='macro'))\n",
    "    f33 = \"{:.2f}\".format(f1_score(y_test3, y_gauss, average='macro'))\n",
    "    roc1 = \"{:.2f}\".format(roc_auc_score(y_test1, y_linear))\n",
    "    roc2 = \"{:.2f}\".format(roc_auc_score(y_test2, y_poly))\n",
    "    roc3 = \"{:.2f}\".format(roc_auc_score(y_test3, y_gauss))\n",
    "    a1,a2 = confusion_matrix(y_test1, y_linear)[0],confusion_matrix(y_test1, y_linear)[1]\n",
    "    b1,b2 = confusion_matrix(y_test2, y_poly)[0],confusion_matrix(y_test2, y_poly)[1]\n",
    "    c1,c2 = confusion_matrix(y_test3, y_gauss)[0],confusion_matrix(y_test3, y_gauss)[1]\n",
    "    data_rows = [('training time',time1, time2, time3),\n",
    "                 ('','','',''),\n",
    "                  ('accuracy %',linear_accuracy, poly_accuracy, gauss_accuracy),\n",
    "                 ('','','',''),\n",
    "                 ('confusion matrix',a1, b1, c1),\n",
    "                ('',a2,b2,c2),\n",
    "                 ('','','',''),\n",
    "                ('f1 score',f11,f22,f33),\n",
    "                 ('','','',''),\n",
    "                ('roc_auc_score',roc1,roc2,roc3)]\n",
    "    t = Table(rows=data_rows, names=('metric','Linear kernel', 'polynomial kernel', 'gaussian kernel'))\n",
    "    print(t)\n",
    "    print('\\n\\n')\n",
    "    print('The Roc curves :\\n')\n",
    "    y_pred1 = y_linear\n",
    "    y_pred2 = y_poly\n",
    "    y_pred3 = y_gauss\n",
    "    fig, _ = plt.subplots()\n",
    "    fig.suptitle('Comparison of three ROC curves')\n",
    "    fpr,tpr,thresholds=roc_curve(y_test1,y_pred1)\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label='Linear kernel :'+str(roc1))\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    fpr,tpr,thresholds=roc_curve(y_test2,y_pred2)\n",
    "    plt.plot(fpr,tpr,label='Polynomial kernel :'+str(roc2))\n",
    "    fpr,tpr,thresholds=roc_curve(y_test3,y_pred3)\n",
    "    plt.plot(fpr,tpr,label='Gaussian kernel :'+str(roc3))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Print results of the choosen kernel\n",
    "\n",
    "def best_kernel(kernel):\n",
    "    X_train1,X_val1,X_test1,y_train1,y_val1,y_test1 = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state1)\n",
    "    X_train2,X_val2,X_test2,y_train2,y_val2,y_test2 = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state2)\n",
    "    X_train3,X_val3,X_test3,y_train3,y_val3,y_test3 = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state3)\n",
    "    \n",
    "    time = 0\n",
    "    f1 = 0\n",
    "    accuracy = 0\n",
    "    rc = 0\n",
    "    y = 0\n",
    "    if kernel == 'linear kernel':\n",
    "        time = time1\n",
    "        f1 = \"{:.2f}\".format(f1_score(y_test1, y_linear, average='macro'))\n",
    "        accuracy = round(100*linear_accuracy)/100\n",
    "        rc = round(100*roc_auc_score(y_test1, y_linear))/100\n",
    "        y_test = y_test1\n",
    "        y = y_linear\n",
    "    elif kernel == 'polynomial kernel':\n",
    "        time = time2\n",
    "        f1 = \"{:.2f}\".format(f1_score(y_test2, y_poly, average='macro'))\n",
    "        accuracy = round(100*poly_accuracy)/100\n",
    "        rc = round(100*roc_auc_score(y_test2, y_poly))/100\n",
    "        y_test = y_test2\n",
    "        y = y_poly\n",
    "    else :\n",
    "        time = time3\n",
    "        f1 = \"{:.2f}\".format(f1_score(y_test3, y_gauss, average='macro'))\n",
    "        accuracy = round(100*gauss_accuracy)/100\n",
    "        rc = round(100*roc_auc_score(y_test3, y_gauss))/100\n",
    "        y_test = y_test3\n",
    "        y = y_gauss \n",
    "        \n",
    "    # used for comparing three classfiers(knn, logistic regression and svm)\n",
    "    yt_svm,yp_svm = y_test, y\n",
    "    \n",
    "    print('The choosen kernel :',kernel)\n",
    "    print('the training :',time)\n",
    "    print('the accuracy :',round(accuracy),'%')\n",
    "    print('the f1 score :',f1)\n",
    "    print('The roc_auc_score is :',rc)\n",
    "    print('----------------------------------------\\nThe ROC curve :')\n",
    "    fig, _ = plt.subplots()\n",
    "    fpr,tpr,thresholds=roc_curve(y_test,y)\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label=kernel+': '+str(rc))\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    confusionMatrix = confusion_matrix(y_test, y)\n",
    "    print('----------------------------------------\\nThe confusion matrix is  :')\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(confusionMatrix,annot=True)\n",
    "    ax.set_title('Confusion matrix of SVM '+str(kernel))\n",
    "    return yt_svm,yp_svm\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# svm factor : factor affecting students performance, later on on this Ipython notebook  we will explain how we will do this\n",
    "\n",
    "\n",
    "# 1) factor as svm coefficients\n",
    "def factors(array, K, max_or_min, df):\n",
    "    \n",
    "    n = array.shape[1]\n",
    "    array = array.reshape(n,1)\n",
    "    my_list = array.tolist()\n",
    "    \n",
    "    if max_or_min == 'max':\n",
    "        temp = sorted(my_list)[-K:]\n",
    "        res = [] \n",
    "        for ele in temp: \n",
    "            res.append(my_list.index(ele))\n",
    "        return(get_factors(res, df))\n",
    "    \n",
    "    \n",
    "    elif max_or_min == 'min':\n",
    "        temp = sorted(my_list, reverse=True)[-K:]\n",
    "        temp = temp = np.array(temp).reshape(K,1)\n",
    "        res = []\n",
    "        for ele in temp:\n",
    "            if ele<0:\n",
    "                res.append(my_list.index(ele))\n",
    "        return(get_factors(res, df))\n",
    "    \n",
    "\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "\n",
    "# 2) converts those factors to dataset columns name\n",
    "def get_factors(index, df):\n",
    "    f = []\n",
    "    for i in index:\n",
    "        f.append(df.columns[i])\n",
    "    return f\n",
    "    \n",
    "\n",
    "# 3) Convert column names to understandable string\n",
    " \n",
    "columns_name = {'famsize': 'family size', 'Pstatus': \"parent's cohabitation status \", 'Medu': \"mother's education\",\n",
    "                'Fedu': \"father's education\", 'Mjob': \"mother's job\", 'Fjob': \"father's job\", \n",
    "                'reason': 'reason to choose this school ','schoolsup': 'extra educational support', 'famsup': 'family educational support',\n",
    "                'paid': 'extra paid classes within the course subject', 'higher': 'wants to take higher education',\n",
    "                'romantic': 'with a romantic relationship ', 'famrel': 'quality of family relationships', 'goout': 'going out with friends',\n",
    "                'Dalc': 'workday alcohol consumption', 'Walc': 'weekend alcohol consumption'}        \n",
    "\n",
    "\n",
    "def column_to_string(fcts,max_or_min):\n",
    "    \n",
    "    if max_or_min == 'max':\n",
    "        print('-----------------------------------------------------------------------------------')\n",
    "        print('Factors helping students succeed :')\n",
    "    else:\n",
    "        print('-----------------------------------------------------------------------------------')\n",
    "        print('-----------------------------------------------------------------------------------')\n",
    "        print('Factors leading students to failure')\n",
    "        \n",
    "    for fct in fcts:\n",
    "        if fct in columns_name:\n",
    "            print(columns_name[fct])\n",
    "        else:\n",
    "            print(fct)\n",
    "    \n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Splitting the data for SVM\n",
    "# Here We will split data into test set, cross validation (X_val, y_val) set and training set\n",
    "# The cross validation (X_val, y_val) is used for choosing the optimal value for svm parameters C, degree and gamma\n",
    "\n",
    "def split(df,rest_size,test_size,randomState):\n",
    "    data = df.to_numpy()\n",
    "    n = data.shape[1]\n",
    "    x = data[:,0:n-1]\n",
    "    y = data[:,n-1]\n",
    "    if(randomState):\n",
    "        X_train,X_rest,y_train,y_rest = train_test_split(x,y,test_size=rest_size,random_state=randomState)\n",
    "        X_val,X_test,y_val,y_test = train_test_split(X_rest,y_rest,test_size=test_size,random_state=randomState)\n",
    "    else:\n",
    "        X_train,X_rest,y_train,y_rest = train_test_split(x,y,test_size=rest_size,random_state=0)\n",
    "        X_val,X_test,y_val,y_test = train_test_split(X_rest,y_rest,test_size=test_size,random_state=0)\n",
    "    \n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test\n",
    "# We will use the three different svm classifier kernels\n",
    "# Linear kernel, polynomial kernel and gaussian kernel and we will choose the most accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWVYFyqODh3P"
   },
   "source": [
    "<h2><span style='color:#b846a3;font-family:Comic Sans MS'>1) Model evaluation: :</span></h2>\n",
    "\n",
    "For model evaluation we will calculate :\n",
    "\n",
    "- <span style='color:red'>**Training time**</span>\n",
    "- <span style='color:red'>**Accuracy**</span>\n",
    "- <span style='color:red'>**Confusion matrix**</span>\n",
    "- <span style='color:red'>**ROC curve**</span>\n",
    "- <span style='color:red'>**ROC score**</span>\n",
    "- <span style='color:red'>**f1 score**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LacqV8JXDh3P"
   },
   "source": [
    "<h2><span style='color:#b846a3;font-family:Comic Sans MS'>2) Training phase :</span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA4jFlb6Dh3P"
   },
   "source": [
    "<h3><span style='color:#0759e6;font-family:Rockwell'>I. Linear Kernel :</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "glotbT0_Dh3P",
    "outputId": "b6d6cd73-4f6a-46c2-bba5-4c8c5381e26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "###################################################### Linear kernel ###########################################################\n",
    "optimal_split_state1 = 0\n",
    "maxAccuracy = 0\n",
    "maxF1 = 0\n",
    "\n",
    "# We already tune parameters, we do not need to loop over all the hyperparamters again, \n",
    "# if you want to do so just set max_iteration to 2000 for example \n",
    "# and remove the line 'optimal_split_state = 388628375' at the bottom of this cell.\n",
    "\n",
    "max_iteration = 0\n",
    "if max_iteration != 0:\n",
    "    print ('----------------------------------------Hyperparameters tunning starts----------------------------------------\\n\\n')\n",
    "\n",
    "for k in range(max_iteration):\n",
    "    print ('Iteration :'+str(k)+', Current accuracy: '+str(maxAccuracy)+' Current f1 '+str(maxF1), end=\"\\r\")\n",
    "    # Let's get the optimal C value for the linear kernal\n",
    "    split_state = np.random.randint(1,1000000000)-1\n",
    "    X_train,X_val,X_test,y_train,y_val,y_test = split(df,rest_size=0.4,test_size=0.4,randomState=split_state)\n",
    "    optimal_C = optimal_C_value()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Now let's use the optimal C value\n",
    "    linear_clf = SVC(C=optimal_C,kernel='linear')\n",
    "\n",
    "    # Let's train the model with the optimal C value and calculate the training time\n",
    "    tic = time()\n",
    "    linear_clf.fit(X_train, y_train)\n",
    "    toc = time()\n",
    "    time1 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "    y_linear = linear_clf.predict(X_test)\n",
    "    linear_f1 = f1_score(y_test, y_linear, average='macro')\n",
    "    linear_accuracy = accuracy_score(y_test, y_linear)*100\n",
    "    if linear_accuracy>maxAccuracy and linear_f1>maxF1:\n",
    "        maxAccuracy = linear_accuracy\n",
    "        maxF1 = linear_f1\n",
    "        optimal_split_state1 = split_state\n",
    "    if maxAccuracy>86 and maxF1>80:\n",
    "        break;\n",
    "        \n",
    "# We've already tuned our hyperparameters, we will not repeat that again as it takes soo long. \n",
    "# The optimal split state for linear kernel is 388628375\n",
    "# Let's try that split state \n",
    "optimal_split_state1 = 388628375\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state1)\n",
    "optimal_C = optimal_C_value()\n",
    "print(optimal_C)\n",
    "\n",
    "\n",
    "# Now let's use the optimal C value\n",
    "linear_clf = SVC(C=optimal_C,kernel='linear')\n",
    "\n",
    "# Let's train the model with the optimal C value and calculate the training time\n",
    "tic = time()\n",
    "linear_clf.fit(X_train, y_train)\n",
    "toc = time()\n",
    "time1 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "y_linear = linear_clf.predict(X_test)\n",
    "linear_accuracy = accuracy_score(y_test, y_linear)*100\n",
    "if max_iteration != 0:\n",
    "    print('\\n\\n\\n                            ---------------------------process ended'\\\n",
    "         '------------------------------------                            \\n\\n\\n')\n",
    "\n",
    "# Let's show the resuls\n",
    "# showResults(linear_accuracy, time1, y_linear,'SVM linear kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ1FHcT3Dh3Q",
    "outputId": "777d413d-c651-4941-eba6-6ffe4e57b2fb"
   },
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R8H4mQSDh3Q",
    "outputId": "0ef726d7-73ab-4fb5-a67b-c1b4ba5433da"
   },
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TnbuquEDh3Q"
   },
   "source": [
    "<h6>Conclusion</h6>\n",
    "\n",
    "   - As you can see the metrics show that our linear kernel svm classifier is very effective, an accuracy of **84 %** is much acceptable for our problem, the confusion matric is roughly diagonal which indicate that our classifier is able to label your data correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK_fR4-sDh3R"
   },
   "source": [
    "<h3><span style='color:#0759e6;font-family:Rockwell'>II. Polynomial Kernel :</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUqwy19JDh3R",
    "outputId": "18bd58d4-d81a-48bc-8f84-3edbfae1c2bc"
   },
   "outputs": [],
   "source": [
    "###################################################### Polynomial kernel #######################################################\n",
    "optimal_split_state2 = 0\n",
    "maxAccuracy = 0\n",
    "maxF1 = 0\n",
    "\n",
    "\n",
    "# We already tune parameters, we do not need to loop over all the hyperparamters again, \n",
    "# if you want to do so just set max_iteration to 500 for example \n",
    "# and remove the line 'optimal_split_state2 = 7070621' at the bottom of this cell.\n",
    "\n",
    "max_iteration = 0\n",
    "if max_iteration != 0:\n",
    "    print ('----------------------------------------Hyperparameters tunning starts----------------------------------------\\n\\n')\n",
    "for k in range(max_iteration):\n",
    "    print ('Iteration :'+str(k)+', Current accuracy: '+str(maxAccuracy)+', Current f1 '+str(maxF1), end=\"\\r\")\n",
    "    \n",
    "    split_state = np.random.randint(1,100000000)-1\n",
    "    X_train,X_val,X_test,y_train,y_val,y_test = split(df,rest_size=0.4,test_size=0.4,randomState=split_state)\n",
    "\n",
    "    # Let's get the optimal C and the degree value for the polynomial kernal\n",
    "    optimal_C, optimal_d = optimal_C_d_values()\n",
    "    \n",
    "    # Now let's use the optimal c value and the optimal degree value\n",
    "    poly_clf = SVC(C=optimal_C,kernel='poly', degree=optimal_d)\n",
    "\n",
    "    # Let's train the model with the optimal C value \n",
    "    poly_clf.fit(X_train, y_train)\n",
    "    y_poly = poly_clf.predict(X_test)\n",
    "    poly_f1 = f1_score(y_test, y_poly, average='macro')\n",
    "    poly_accuracy = accuracy_score(y_test, y_poly)*100\n",
    "    \n",
    "    if poly_accuracy>maxAccuracy and poly_f1>maxF1:\n",
    "        maxAccuracy = poly_accuracy\n",
    "        maxF1 = poly_f1\n",
    "        optimal_split_state2 = split_state\n",
    "\n",
    "# We've already tuned our hyperparameters, we will not repeat that again as it takes soo long. \n",
    "# The optimal split state for polynomial kernel is 7070621\n",
    "# Let's try that split state \n",
    "optimal_split_state2 = 7070621\n",
    "\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state2)\n",
    "\n",
    "optimal_C, optimal_d = optimal_C_d_values()\n",
    "\n",
    "\n",
    "# Now let's use the optimal C value\n",
    "poly_clf = SVC(C=optimal_C,kernel='poly', degree=optimal_d)\n",
    "\n",
    "# Let's train the model and calculate the training time\n",
    "tic = time()\n",
    "poly_clf.fit(X_train, y_train)\n",
    "toc = time()\n",
    "time2 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "y_poly = poly_clf.predict(X_test)\n",
    "poly_accuracy = accuracy_score(y_test, y_poly)*100\n",
    "if max_iteration != 0:\n",
    "    print('\\n\\n\\n                            ---------------------------process ended'\\\n",
    "         '------------------------------------                            \\n\\n\\n')\n",
    "\n",
    "# Let's show the resuls\n",
    "showResults(poly_accuracy, time2, y_poly,'SVM polynomial kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBvPDylLDh3R"
   },
   "source": [
    "<h6>Conclusion</h6>\n",
    "\n",
    "   - As you can see the metrics show that our polynomial kernel svm classifier is not effective that much, an accuracy of **78 %** is not that good for our problem, the confusion matric indicates that our classifier miss labeled some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqJ5yd2LDh3S"
   },
   "source": [
    "<h3><span style='color:#0759e6;font-family:Rockwell'>III. Gaussian Kernel :</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HlT6fTrDh3S",
    "outputId": "7d1bae8a-c298-4c90-a50e-1b42ef3cc6ad"
   },
   "outputs": [],
   "source": [
    "###################################################### Gaussian kernel ######################################################\n",
    "optimal_split_state3 = 0\n",
    "maxAccuracy = 0\n",
    "maxF1 = 0\n",
    "\n",
    "\n",
    "# We already tune parameters, we do not need to loop over all the hyperparamters again, \n",
    "# if you want to do so just set max_iteration to 500 for example \n",
    "# and remove the line 'optimal_split_state3 = 93895097' at the bottom of this cell.\n",
    "\n",
    "max_iteration = 0\n",
    "if max_iteration != 0:\n",
    "    print ('----------------------------------------------Hyperparameters tunning starts'\\\n",
    "          '--------------------------------------------\\n\\n')\n",
    "for k in range(max_iteration):\n",
    "    print ('Iteration :'+str(k)+', Current accuracy: '+str(maxAccuracy)+', Current f1 '+str(maxF1), end=\"\\r\")\n",
    "    \n",
    "    split_state = np.random.randint(1,100000000)-1\n",
    "    X_train,X_val,X_test,y_train,y_val,y_test = split(df,rest_size=0.4,test_size=0.4,randomState=split_state)\n",
    "\n",
    "    # Let's get the optimal C and the degree value for the polynomial kernal\n",
    "    optimal_C, optimal_gamma = optimal_C_gamma_values()\n",
    "    \n",
    "    # Now let's use the optimal c value and the optimal degree value\n",
    "    gauss_clf = SVC(C=optimal_C,kernel='rbf',gamma=optimal_gamma)\n",
    "\n",
    "    # Let's train the model with the optimal C value \n",
    "    gauss_clf.fit(X_train, y_train)\n",
    "    y_gauss = gauss_clf.predict(X_test)\n",
    "    gauss_f1 = f1_score(y_test, y_gauss, average='macro')\n",
    "    gauss_accuracy = accuracy_score(y_test, y_gauss)*100\n",
    "    \n",
    "    if gauss_accuracy>maxAccuracy and gauss_f1>maxF1:\n",
    "        maxAccuracy = gauss_accuracy\n",
    "        maxF1 = gauss_f1\n",
    "        optimal_split_state3 = split_state\n",
    "\n",
    "# We've already tuned our hyperparameters, we will not repeat that again as it takes soo long. \n",
    "# The optimal split state for polynomial kernel is 93895097\n",
    "# Let's try that split state \n",
    "optimal_split_state3 = 93895097\n",
    "\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = split(df,rest_size=0.4,test_size=0.4,randomState=optimal_split_state3)\n",
    "\n",
    "optimal_C, optimal_gamma = optimal_C_gamma_values()\n",
    "\n",
    "\n",
    "# Now let's use the optimal C value\n",
    "gauss_clf = SVC(C=optimal_C,kernel='rbf',gamma=optimal_gamma)\n",
    "\n",
    "# Let's train the model and calculate the training time\n",
    "tic = time()\n",
    "gauss_clf.fit(X_train, y_train)\n",
    "toc = time()\n",
    "time3 = str(round(1000*(toc-tic))) + \"ms\"\n",
    "y_gauss = gauss_clf.predict(X_test)\n",
    "gauss_accuracy = (accuracy_score(y_test, y_gauss)*100)\n",
    "\n",
    "if max_iteration != 0:\n",
    "    print('\\n\\n\\n                            ---------------------------process ended'\\\n",
    "         '------------------------------------                            \\n\\n\\n')\n",
    "                                                                \n",
    "# Let's show the resuls\n",
    "showResults(gauss_accuracy, time3, y_gauss,'SVM gaussian kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr9-v2IGDh3S"
   },
   "source": [
    "<h6>Conclusion</h6>\n",
    "\n",
    "   - As you can see the metrics show that our gaussian kernel svm classifier is not effective comparing to linear kernel classifier, an accuracy of **78 %** is not that good for our problem, the confusion matric indicates that this classifier also miss labeled some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcQ7wT3bDh3S"
   },
   "source": [
    "<h2><span style='color:#b846a3;font-family:Comic Sans MS'>3) Comparison of the three svm kernels: </span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlK2e9O_Dh3T",
    "outputId": "56a7d593-4b6e-4add-fb19-3a54c0deba26"
   },
   "outputs": [],
   "source": [
    "compare_kernels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWergA8XDh3T"
   },
   "source": [
    "<h6>Conclusion :</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6fdB5LADh3d",
    "outputId": "3a05195d-d7ad-4c93-fd6c-f878908f1496",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yt_svm,yp_svm = best_kernel('linear kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbgHzP-lDh3e"
   },
   "source": [
    "<h4 style='color:red'>Let's test our function :</h4>\n",
    "    \n",
    "   - Let's take five factors for the two classes ($class\\ 0: did\\ not\\ passed, class 1: passed$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2awcuHxWDh3e",
    "outputId": "8a31dcfe-11f1-4a48-ec52-400446d85356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38240047 -0.14115993 -0.47225722 -0.0873321   0.02378315  0.28185403\n",
      "   0.18508527  0.39119246 -0.24120781  0.73554836  0.10126125  0.41365275\n",
      "   0.30414303  0.70686316 -2.11420415 -0.16774523 -0.41001245  0.1349852\n",
      "   0.09413791 -0.24409527  0.48846944 -0.01051673 -0.01956946 -0.17158471\n",
      "   0.31849448 -0.89450701  0.14427766 -0.04127621 -0.47325929 -1.81767219]]\n",
      "-----------------------------------------------------------------------------------\n",
      "Factors helping students succeed :\n",
      "father's education\n",
      "guardian\n",
      "wants to take higher education\n",
      "studytime\n",
      "father's job\n",
      "-----------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------\n",
      "Factors leading students to failure\n",
      "age\n",
      "health\n",
      "going out with friends\n",
      "absences\n",
      "failures\n"
     ]
    }
   ],
   "source": [
    "# Get svm parameters\n",
    "coefs = linear_clf.coef_\n",
    "print(coefs)\n",
    "\n",
    "# factors helping students to succeed\n",
    "column_to_string(factors(coefs, 5, 'max', df),'max')\n",
    "\n",
    "# factors leading students to failure\n",
    "column_to_string(factors(coefs, 5, 'min', df), 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sxl0KFi_Dh3f"
   },
   "source": [
    "# Comparison of the three algorithms <"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Szrlix0HDh3f"
   },
   "outputs": [],
   "source": [
    "# Function to compare the three classifiers (Logistic regression, KNN and SVM) performances :\n",
    "\n",
    "def compare_lg_knn_svm(yt_knn,yp_knn,yt_lg,yp_lg,yt_svm,yp_svm):\n",
    "    #F1 score\n",
    "    f1_lg = round(f1_score(yt_lg, yp_lg, average='macro')*100)\n",
    "    f1_knn = round(f1_score(yt_knn, yp_knn, average='macro')*100)\n",
    "    f1_svm = round(f1_score(yt_svm, yp_svm, average='macro')*100)\n",
    "    \n",
    "    #Accuracy score\n",
    "    acc_lg = round(accuracy_score(yt_lg, yp_lg)*100)\n",
    "    acc_knn = round(accuracy_score(yt_knn, yp_knn)*100)\n",
    "    acc_svm = round(accuracy_score(yt_svm, yp_svm)*100)\n",
    "    \n",
    "    #Confusion matrix\n",
    "    conf_lg = confusion_matrix(yt_lg, yp_lg)\n",
    "    conf_knn = confusion_matrix(yt_knn, yp_knn)\n",
    "    conf_svm = confusion_matrix(yt_svm, yp_svm)\n",
    "    \n",
    "    #ROC score\n",
    "    roc_c_lg = round(roc_auc_score(yt_lg, yp_lg)*100)\n",
    "    roc_c_knn = round(roc_auc_score(yt_knn, yp_knn)*100)\n",
    "    roc_c_svm = round(roc_auc_score(yt_svm, yp_svm)*100)\n",
    "    \n",
    "    #ROC curve thresholds\n",
    "    roc_knn = roc_curve(yt_knn,yp_knn)\n",
    "    roc_lg = roc_curve(yt_lg,yp_lg)\n",
    "    roc_svm = roc_curve(yt_svm,yp_svm)\n",
    "    \n",
    "    # Table of metrics\n",
    "    print('-----------------------------Table of metrics--------------------------------------\\n\\n')\n",
    "    data_rows = [('f1 score',f1_lg,f1_knn,f1_svm),\n",
    "                 ('','','',''),\n",
    "                  ('accuracy %',acc_lg,acc_knn,acc_svm),\n",
    "                 ('','','',''),\n",
    "                 ('confusion matrix',conf_lg[0], conf_knn[0], conf_svm[0]),\n",
    "                ('',conf_lg[1], conf_knn[1], conf_svm[1]),\n",
    "                 ('','','',''),\n",
    "                ('ROC score',roc_c_lg,roc_c_knn,roc_c_svm)]\n",
    "    t = Table(rows=data_rows, names=('metric','Logistic regression', 'KNN', 'SVM'))\n",
    "    print(t)\n",
    "    \n",
    "    #Plot ROC curve\n",
    "    print('\\n\\n-----------------------------ROC curves--------------------------------------\\n\\n')\n",
    "    fig, _ = plt.subplots()\n",
    "    fig.suptitle('Comparison of three ROC curves')\n",
    "    fpr,tpr,thresholds=roc_lg\n",
    "    plt.plot([0, 1],[0, 1],'--')\n",
    "    plt.plot(fpr,tpr,label='Logistic regression :'+str(roc_c_lg))\n",
    "    plt.xlabel('false positive')\n",
    "    plt.ylabel('false negative')\n",
    "    fpr,tpr,thresholds=roc_knn\n",
    "    plt.plot(fpr,tpr,label='KNN :'+str(roc_c_knn))\n",
    "    fpr,tpr,thresholds=roc_svm\n",
    "    plt.plot(fpr,tpr,label='SVM :'+str(roc_c_svm))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Maximum metrics\n",
    "    print('-----------------------------Max of metrics--------------------------------------\\n\\n')\n",
    "    data_rows = [('max f1 score',algo_with_max_metric(f1_lg,f1_knn,f1_svm)),\n",
    "                 ('','','',''),\n",
    "                  ('max accuracy %',algo_with_max_metric(acc_lg,acc_knn,acc_svm)),\n",
    "                 ('','','',''),\n",
    "                ('max ROC score',algo_with_max_metric(roc_c_lg,roc_c_knn,roc_c_svm))]\n",
    "    t = Table(rows=data_rows, names=('metric','Learning algorithm winnig'))\n",
    "    print(t)\n",
    "    \n",
    "# Function returning name of winnig algorithm based on a single metric\n",
    "def algo_with_max_metric(a,b,c):\n",
    "    max_metric = max(a,b,c)\n",
    "    if max_metric == a:\n",
    "        return 'Logistic regression'\n",
    "    elif max_metric == b:\n",
    "        return 'KNN'\n",
    "    else:\n",
    "        return 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9o1n6bADh3f",
    "outputId": "858e3f64-5930-4396-e741-1529a07077c8"
   },
   "outputs": [],
   "source": [
    "compare_lg_knn_svm(yt_knn,yp_knn,yt_lg,yp_lg,yt_svm,yp_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3zjb8SZDh3g"
   },
   "source": [
    "# Analyse the Learning Outcomes of a Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "G07kBi3KDh3g"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import random\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9rC_T_uMDh3g"
   },
   "outputs": [],
   "source": [
    "question = input(\"Enter a Question: \")\n",
    "words = [re.sub(r'[^a-zA-Z]', '', i) for i in question.split(' ')]\n",
    "learning_outcomes = ['KNOWLEDGE', 'COMPREHENSION', 'APPLICATION', 'ANALYSIS', 'SYNTHESIS', 'EVALUATION']\n",
    "lo_values = {'KNOWLEDGE':0, 'COMPREHENSION':0, 'APPLICATION':0, 'ANALYSIS':0, 'SYNTHESIS':0, 'EVALUATION':0}\n",
    "for word in words:\n",
    "    #root_word = stemmer.stem(word)\n",
    "    #print(\"root-word: \", root_word)\n",
    "    for outcome in learning_outcomes:\n",
    "        if word.capitalize() in domain[outcome]:\n",
    "            lo_values[outcome] += 1\n",
    "            \n",
    "valmax = max(zip(lo_values.values(), lo_values.keys()))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0QAYpYSDh3h"
   },
   "source": [
    "# Analysis of Student Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "v3FGuJxkDh3h",
    "outputId": "bb83d5b8-f54b-400e-a828-5697c81437a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent's Education Level: Numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - Secondary Education or 4 - Higher Education\n",
      "Guardian - Numeric Mother:0, Father:1, Other:2\n",
      "Study time - Numeric 1 : <2 hours, 2 : 2 to 5 hours, 3 : 5 to 10 hours, 4 : >10 hours\n",
      "Travel time - Numeric 1 : <15 min., 2 : 15 to 30 min., 3 : 30 min. to 1 hour, or 4 : >1 hour\n"
     ]
    }
   ],
   "source": [
    "school = int(input('Enter Education level (High-School:0 / University:1): '))\n",
    "gender = int(input('Gender (M:0 / F:1): '))\n",
    "age = int(input('Age: '))\n",
    "address = int(input('Urban(0) /Rural(1): '))\n",
    "famsize = int(input('Family size (0:<3 / 1:>3): '))\n",
    "Pstatus = int(input('Parents: Living-Together(0)/Apart(1): '))\n",
    "print(\"Parent's Education Level: Numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - Secondary Education or 4 - Higher Education\")\n",
    "Medu = int(input(\"Mother's Education: \"))\n",
    "Fedu = int(input(\"Father's Education: \"))\n",
    "Mjob = random.randint(0, 4)\n",
    "Fjob = random.randint(0, 4)\n",
    "reason = random.randint(0, 4)\n",
    "print('Guardian - Numeric Mother:0, Father:1, Other:2')\n",
    "guardian = int(input('Guardian: '))\n",
    "print('Study time - Numeric 1 : <2 hours, 2 : 2 to 5 hours, 3 : 5 to 10 hours, 4 : >10 hours')\n",
    "studytime = int(input('Study Time: '))\n",
    "print('Travel time - Numeric 1 : <15 min., 2 : 15 to 30 min., 3 : 30 min. to 1 hour, or 4 : >1 hour')\n",
    "traveltime = int(input('Travel Time: '))\n",
    "failures = int(input('Number of Failures(0-4): '))\n",
    "schoolsup = random.randint(0, 1)\n",
    "famsup = 0 if schoolsup==1 else 1\n",
    "paid = int(input(\"Taking Extra-Classes (1:Yes / 0:No): \"))\n",
    "activities = int(input(\"Involved in Sports activities (1:Yes / 0:No): \"))\n",
    "nursery = random.randint(0, 1)\n",
    "higher = int(input(\"Plan to take Higher Education (1:Yes / 0:No): \"))\n",
    "internet = int(input('Internet access at home (1:Yes / 0:No): '))\n",
    "romantic = random.randint(0, 1)\n",
    "famrel = random.randint(1, 5)\n",
    "freetime = int(input('Free Time after School (1-5): '))\n",
    "goout = int(input('Spending free time with Friends: (1-5): '))\n",
    "Dalc = 0\n",
    "Walc = int(input(\"Habit of Alcohol Consumption (1:Yes / 0:No): \"))\n",
    "health = int(input(\"Current health status (0-Healthy - 5-Bad health)\"))\n",
    "absences = int(input(\"Range of absences at School/University (0-5): \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RlWDyiJrDh3h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "array = [[school, gender, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, guardian, studytime, traveltime, failures, \n",
    "         schoolsup, famsup, paid, activities, nursery, higher, internet, romantic, famrel, freetime, goout, Dalc, Walc, health, absences]]\n",
    "\n",
    "result = linear_clf.predict(array)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "glGdspJ8Dh3h",
    "outputId": "c4b891ce-3561-4a33-804b-1788a9fdea03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is your name?\n",
      "Learning Outcomes: \n",
      "KNOWLEDGE: 1.0\n",
      "The Student can answer\n"
     ]
    }
   ],
   "source": [
    "print(\"Question: \"+question)\n",
    "print(\"Learning Outcomes: \")\n",
    "\n",
    "for outcome in learning_outcomes:\n",
    "    if lo_values[outcome]>0:\n",
    "        print(\"{0}: {1}\".format(outcome, (lo_values[outcome]/valmax)))\n",
    "      \n",
    "if result:\n",
    "    print(\"The Student maynot answer the question\")\n",
    "else:\n",
    "    print(\"The Student can answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-aMmbbnDh3i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MvneVCTUDh2z",
    "RoyMzEJcDh21",
    "9YKpjgdkDh22",
    "cPfQC12IDh22",
    "wpiztrehDh23",
    "c3a60vK_Dh24",
    "mmvtUWv3Dh25",
    "CHnwgzTkDh27",
    "2bLCEl_rDh28",
    "JJyEQnVuDh29",
    "ta6ras2DDh2-",
    "JdEcNSykDh2_",
    "BD8jZ99yDh3A",
    "yTi__vkvDh3B",
    "q77ninj_Dh3B",
    "8Eyv28jbDh3C",
    "j9fIzwzJDh3E",
    "zpTxB4VlDh3G",
    "0oAUrjGhDh3H",
    "7FVsdKXnDh3K",
    "A6XAz5ymDh3L",
    "Je5UFYCJDh3N",
    "Sxl0KFi_Dh3f"
   ],
   "name": "code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
