{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagestore=[]\n",
    "video_source_path= \"data_set_final\"\n",
    "fps=2 # skips 1 fps\n",
    "def create_dir(path):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)\n",
    "def remove_images(path):\n",
    "\tfilelist = glob.glob(os.path.join(path, \"*.png\"))\n",
    "\tfor f in filelist:\n",
    "\t\tos.remove(f)\n",
    "\n",
    "def store(image_path):\n",
    "\timg = cv.imread(image_path)\n",
    "\tgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\tgray = cv.resize(gray,(227,227),interpolation=cv.INTER_LINEAR_EXACT)\n",
    "\timagestore.append(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = os.listdir(video_source_path)\n",
    "create_dir(video_source_path+'/frames')\n",
    "remove_images(video_source_path+'/frames')\n",
    "framepath = video_source_path+'/frames'\n",
    "for video in videos:\n",
    "\t\tos.system( 'ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format(video_source_path,video,fps,video_source_path))\n",
    "\t\timages=os.listdir(framepath)\n",
    "\t\tfor image in images:\n",
    "\t\t\timage_path=framepath+ '/'+ image\n",
    "\t\t\tstore(image_path)\n",
    "\t\t\t\n",
    "imagestore=np.array(imagestore)\n",
    "print(imagestore.shape)\n",
    "a,b,c=imagestore.shape\n",
    "imagestore.resize(b,c,a)\n",
    "imagestore=(imagestore-imagestore.mean())/(imagestore.std())\n",
    "imagestore=np.clip(imagestore,0,1)\n",
    "np.save('training.npy',imagestore)\n",
    "os.system('rm -r {}'.format(framepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading training data which is in .npy file\n",
    "X_train=np.load('training.npy')\n",
    "print(X_train.shape)\n",
    "frames=X_train.shape[2]\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=frames-frames%10\n",
    "\n",
    "print(frames)\n",
    "\n",
    "X_train=X_train[:,:,:frames]\n",
    "print(X_train.shape)\n",
    "# reshaping Xtrain to 10 X 1 X 227 X 227\n",
    "\n",
    "X_train=X_train.reshape(-1,227,227,1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# X_train=np.expand_dims(X_train,axis=4)\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train=X_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatio Temporal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "\n",
    "\n",
    "    STModel = Sequential()\n",
    "\n",
    "    STModel.add(Conv3D(filters=128, kernel_size=(11, 11, 1), strides=(4, 4, 1), padding='valid', input_shape=(227, 227, 1,1), activation='relu'))\n",
    "    STModel.add(Conv3D(filters=64, kernel_size=(5, 5, 1), strides=(2, 2, 1), padding='valid', activation='relu'))\n",
    "\n",
    "    STModel.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', dropout=0.4, recurrent_dropout=0.3, return_sequences=True))\n",
    "    STModel.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), strides=1, return_sequences=True, padding='same', dropout=0.5))\n",
    "\n",
    "    STModel.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='relu'))\n",
    "    STModel.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='relu'))\n",
    "\n",
    "\n",
    "    STModel.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return STModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=loadModel()\n",
    "\n",
    "save = ModelCheckpoint(\"behaviourtest_3.h5\",\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"mse\", save_best_only=False)\n",
    "\n",
    "\n",
    "\n",
    "stopping_point = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "\n",
    "print('Model has been loaded')\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train,Y_train,\n",
    "\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\tepochs=2,\n",
    "\t\t\t\tcallbacks = [save,stopping_point]\n",
    "\t\t\t\t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "def mean_squared(x1, x2):\n",
    "    difference = x1 - x2\n",
    "    a,b,c,d,e = difference.shape\n",
    "    n_samples = a*b*c*d*e\n",
    "    sq_diff = difference ** 2\n",
    "    Sum = sq_diff.sum()\n",
    "    dist = np.sqrt(Sum)\n",
    "    mean_dist = dist / n_samples\n",
    "    return mean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1.16e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return True if there are abnormal events in Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_anomly(weights_path,path_to_npy_processed_video_file):\n",
    "    model=load_model(weights_path)\n",
    "\n",
    "    X_test=np.load(path_to_npy_processed_video_file)\n",
    "    print(X_test.shape)\n",
    "    frames=X_test.shape[2]\n",
    "\n",
    "    Anomality  = False\n",
    "\n",
    "    frames=frames-frames%10\n",
    "\n",
    "    X_test=X_test[:,:,:frames]\n",
    "    X_test=X_test.reshape(-1,227,227,1)\n",
    "    # X_test=np.expand_dims(X_test,axis=4)\n",
    "    a_frames = []\n",
    "    for number,bunch in enumerate(X_test):\n",
    "        n_bunch=np.expand_dims(bunch,axis=0)\n",
    "        reconstructed_bunch=model.predict(n_bunch)\n",
    "        loss=mean_squared(n_bunch,reconstructed_bunch)\n",
    "        print(loss,end=\"\\r\")\n",
    "        writer.add_scalar(\"anomality\",loss,number)\n",
    "        writer.flush()\n",
    "        if loss>threshold:\n",
    "            print(\"Anomalous frames @ {}\".format(number),end=\"\\r\")\n",
    "            a_frames.append(number)\n",
    "            Anomality = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if len(a_frames) > 0:\n",
    "        \n",
    "        return Anomality,a_frames\n",
    "    else:\n",
    "        a = []\n",
    "        return Anomality,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1l\u001b>[32m\u001b[7m    PID USER DEV    TYPE  GPU \u001b[36m       GPU MEM\u001b[32m    CPU  HOST MEM Command           \u001b[24;1H\u001b[m\u001b[mF2\u001b[36m\u001b[7mSetup   \u001b[m\u001b[mF6\u001b[36m\u001b[7mSort    \u001b[m\u001b[mF9\u001b[36m\u001b[7mKill    \u001b[m\u001b[mF10\u001b[36m\u001b[7mQuit    \u001b[m\u001b[mF12\u001b[36m\u001b[7mSave Config                       \u001b[4h \u001b[4l\u001b[24;56H\u001b[m\u001b[mmq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[36mq\u001b[33mq\u001b[mx\u000f\u001b[17;4H\u000emqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqj\u000f\u001b[18;31H\u001b[24;1H\u001b[2J\u001b[?47l\u001b8"
     ]
    }
   ],
   "source": [
    "! nvtop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_anomly(\"behaviour_2.h5\",\"f4.npy\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
